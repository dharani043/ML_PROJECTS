{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aazA0xuYqgbD",
        "outputId": "25732a2b-d91b-4d9c-da56-322496f9b0a6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 303 entries, 0 to 302\n",
            "Data columns (total 14 columns):\n",
            " #   Column    Non-Null Count  Dtype  \n",
            "---  ------    --------------  -----  \n",
            " 0   age       303 non-null    int64  \n",
            " 1   sex       303 non-null    int64  \n",
            " 2   cp        303 non-null    int64  \n",
            " 3   trestbps  303 non-null    int64  \n",
            " 4   chol      303 non-null    int64  \n",
            " 5   fbs       303 non-null    int64  \n",
            " 6   restecg   303 non-null    int64  \n",
            " 7   thalach   303 non-null    int64  \n",
            " 8   exang     303 non-null    int64  \n",
            " 9   oldpeak   303 non-null    float64\n",
            " 10  slope     303 non-null    int64  \n",
            " 11  ca        303 non-null    int64  \n",
            " 12  thal      303 non-null    int64  \n",
            " 13  target    303 non-null    int64  \n",
            "dtypes: float64(1), int64(13)\n",
            "memory usage: 33.3 KB\n",
            "     age  sex  cp  trestbps  chol  fbs  restecg  thalach  exang  oldpeak  \\\n",
            "0     63    1   3       145   233    1        0      150      0      2.3   \n",
            "1     37    1   2       130   250    0        1      187      0      3.5   \n",
            "2     41    0   1       130   204    0        0      172      0      1.4   \n",
            "3     56    1   1       120   236    0        1      178      0      0.8   \n",
            "4     57    0   0       120   354    0        1      163      1      0.6   \n",
            "..   ...  ...  ..       ...   ...  ...      ...      ...    ...      ...   \n",
            "298   57    0   0       140   241    0        1      123      1      0.2   \n",
            "299   45    1   3       110   264    0        1      132      0      1.2   \n",
            "300   68    1   0       144   193    1        1      141      0      3.4   \n",
            "301   57    1   0       130   131    0        1      115      1      1.2   \n",
            "302   57    0   1       130   236    0        0      174      0      0.0   \n",
            "\n",
            "     slope  ca  thal  \n",
            "0        0   0     1  \n",
            "1        0   0     2  \n",
            "2        2   0     2  \n",
            "3        2   0     2  \n",
            "4        2   0     2  \n",
            "..     ...  ..   ...  \n",
            "298      1   0     3  \n",
            "299      1   0     3  \n",
            "300      1   2     3  \n",
            "301      1   1     3  \n",
            "302      1   1     2  \n",
            "\n",
            "[303 rows x 13 columns]\n",
            "0      1\n",
            "1      1\n",
            "2      1\n",
            "3      1\n",
            "4      1\n",
            "      ..\n",
            "298    0\n",
            "299    0\n",
            "300    0\n",
            "301    0\n",
            "302    0\n",
            "Name: target, Length: 303, dtype: int64\n",
            "(303, 13)\n",
            "(242, 13)\n",
            "(61, 13)\n",
            "61     1\n",
            "238    0\n",
            "160    1\n",
            "158    1\n",
            "289    0\n",
            "      ..\n",
            "100    1\n",
            "49     1\n",
            "300    0\n",
            "194    0\n",
            "131    1\n",
            "Name: target, Length: 242, dtype: int64\n",
            "255    0\n",
            "72     1\n",
            "83     1\n",
            "268    0\n",
            "92     1\n",
            "      ..\n",
            "42     1\n",
            "187    0\n",
            "8      1\n",
            "122    1\n",
            "19     1\n",
            "Name: target, Length: 61, dtype: int64\n",
            "ACCURACY SCORE OF TRAINING DATA SET 0.8512396694214877\n",
            "\n",
            "ACCURACY SCORE OF TRAINING DATA SET 0.819672131147541\n",
            "\n",
            "[1]\n",
            "THE PERSON HAS HEART DISEASE\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LogisticRegression was fitted with feature names\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "import  numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV # Added GridSearchCV based on later code\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "heart_data=pd.read_csv(\"heart.csv\")\n",
        "\n",
        "#display top 5 rows\n",
        "heart_data.head()\n",
        "\n",
        "#display bottom 5 rows\n",
        "heart_data.tail()\n",
        "\n",
        "#display rows and columns\n",
        "heart_data.shape\n",
        "\n",
        "#display no of null values or checking missing values\n",
        "heart_data.isnull().sum()\n",
        "\n",
        "#display the data type and size\n",
        "heart_data.info()\n",
        "\n",
        "#detailed description about dataset(mean,meadian,25%,50%,75%,std,min,max) or statistical measures\n",
        "heart_data.describe()\n",
        "\n",
        "#checking the distribution of target variable\n",
        "heart_data['target'].value_counts()\n",
        "\n",
        "#splitting the features and target\n",
        "x=heart_data.drop(columns='target',axis=1)\n",
        "y=heart_data['target']\n",
        "print(x)\n",
        "print(y)\n",
        "\n",
        "#splitting the data into training data and testing data\n",
        "# x_train,x_test,y_train,y_test=train_test_split(x,y,test_size=0.2,target_state=3)\n",
        "x_train,x_test,y_train,y_test=train_test_split(x,y,test_size=0.2,stratify=y,random_state=2)\n",
        "\n",
        "print(x.shape)\n",
        "print(x_train.shape)\n",
        "print(x_test.shape)\n",
        "print(y_train)\n",
        "print(y_test)\n",
        "\n",
        "#model training\n",
        "model=LogisticRegression()\n",
        "\n",
        "#training the logistic regression with the training data\n",
        "model.fit(x_train,y_train)\n",
        "\n",
        "#model evaluvation through accuracy score\n",
        "#accuracy of training data\n",
        "x_train_prediction=model.predict(x_train)\n",
        "training_data_accuracy=accuracy_score(y_train,x_train_prediction)\n",
        "print(\"ACCURACY SCORE OF TRAINING DATA SET\",training_data_accuracy)\n",
        "\n",
        "print()\n",
        "#accuracy of test data\n",
        "x_test_prediction=model.predict(x_test)\n",
        "testing_data_accuracy=accuracy_score(y_test,x_test_prediction)\n",
        "print(\"ACCURACY SCORE OF TRAINING DATA SET\",testing_data_accuracy)\n",
        "print()\n",
        "#building a predictive system\n",
        "input_data=(63,1,3,145,233,1,0,150,0,2.3,0,0,1)\n",
        "\n",
        "#changing the input data to a numpy array\n",
        "input_data_as_numpy_array=np.asarray(input_data)\n",
        "\n",
        "#reshape the numpy array as we are predicting for only the one instance\n",
        "input_data_reshaped = input_data_as_numpy_array.reshape(1,-1)\n",
        "\n",
        "predict_data=model.predict(input_data_reshaped)\n",
        "print(predict_data)\n",
        "\n",
        "if(predict_data==1):\n",
        "    print(\"THE PERSON HAS HEART DISEASE\")\n",
        "else:\n",
        "    print(\"THE PERSON DOES NOT HAVE HEART DISEASE\")\n",
        "\n",
        "\n",
        "\n",
        "param_grid = {\n",
        "    'C': [0.1, 1, 10],\n",
        "    'kernel': ['linear', 'rbf', 'poly'],\n",
        "    'gamma': ['scale', 'auto', 0.01, 0.001],\n",
        "    'degree': [2, 3]  # only for 'poly' kernel\n",
        "}\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "#saving the trained modelimport pickle\n",
        "filename='Heart_Disease_prediction_trained_model.sav'\n",
        "pickle.dump(model,open(filename,'wb'))\n",
        "#loading the saved model\n",
        "loaded_model=pickle.load(open('Heart_Disease_prediction_trained_model.sav','rb'))"
      ],
      "metadata": {
        "id": "aCj7FjeYOo-r"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}